```python
import torch 
from torch import nn
from d2l import torch as d2l

def conv_block(input_channels,num_channels):
    return nn.Sequential(
        nn.BatchNorm2d(input_channels),nn.ReLU(),
        nn.Conv2d(input_channels,num_channels,kernel_size=3,padding=1))
```


```python
class DenseBlock(nn.Module):
    def __init__(self,num_convs,input_channels,num_channels):
        super(DenseBlock,self).__init__()
        layer = []
        for i in range(num_convs):
            layer.append(conv_block(
                num_channels * i + input_channels,num_channels))
            #DenseNet 的核心思想：每一层都接收前面所有层的输出作为输入（通过通道拼接）。
        self.net = nn.Sequential(*layer)

    def forward(self,X):
        for blk in self.net:
            Y = blk(X)
            #连接通道维度上每个卷积块的输入和输出
            X = torch.cat((X,Y),dim=1)
            #对每个卷积块 blk：
# 用当前 X 作为输入，得到输出 Y（通道数为 num_channels）。
# 将 X 和 Y 在 通道维度（dim=1） 上拼接 → 新的 X 通道数增加 num_channels。
        return X
```


```python
blk = DenseBlock(2,3,10)
#创建一个 Dense Block：包含 2 个卷积块初始输入通道 = 3（如 RGB 图像）每个块输出 10 通道（growth rate k=10）
X = torch.randn(4,3,8,8)
Y = blk(X)
Y.shape
```




    torch.Size([4, 23, 8, 8])




```python
blk = DenseBlock(2,3,10)
X = torch.randn(4,3,8,8)
Y = blk(X)
Y.shape
```




    torch.Size([4, 23, 8, 8])




```python
#过渡层
def  transition_block(input_channels,num_channels):
    return nn.Sequential(
        nn.BatchNorm2d(input_channels),nn.ReLU(),
        nn.Conv2d(input_channels,num_channels,kernel_size=1),
        nn.AvgPool2d(kernel_size=2,stride=2))
    
```


```python
blk = transition_block(23,10)
blk(Y).shape
torch.Size([4,10,4,4])
```




    torch.Size([4, 10, 4, 4])




```python
#DenseNet模型
b1 = nn.Sequential(
    nn.Conv2d(1,64,kernel_size=7,stride=2,padding=3),
    nn.BatchNorm2d(64),nn.ReLU(),
    nn.MaxPool2d(kernel_size=3,stride=2,padding=1))

```


```python
num_channels,growth_rate = 64,32
#rowth_rate = 32：DenseNet 中的核心超参数，表示每个卷积块新增的通道数（即每层输出 32 通道）
num_convs_in_dense_blocks = [4,4,4,4]
#表示网络包含 4 个 Dense Block
# 每个 Dense Block 分别包含 4 个卷积块（即 4 层）
blks  = []
for i,num_convs in enumerate(num_convs_in_dense_blocks):
    blks.append(DenseBlock(num_convs,num_channels,growth_rate))
    #上一个稠密块的输出通道
    num_channels += num_convs*growth_rate
    #在稠密块之间添加一个过渡层，使通道数减半
    if i != len(num_convs_in_dense_blocks) - 1:
        #添加 Transition Layer（除最后一个 Dense Block 外）
        blks.append(transition_block(num_channels,num_channels //2))
        num_channels = num_channels //2
```


```python
net = nn.Sequential(
    b1,*blks,
    nn.BatchNorm2d(num_channels),nn.ReLU(),
    nn.AdaptiveAvgPool2d((1,1)),
    nn.Flatten(),
    nn.Linear(num_channels,10))
```


```python
lr ,num_epochs,batch_size = 0.1,10,256
train_iter,test_iter = d2l.load_data_fashion_mnist(batch_size,resize=96)
d2l.train_ch6(net,train_iter,test_iter,num_epochs,lr,d2l.try_gpu())
```
