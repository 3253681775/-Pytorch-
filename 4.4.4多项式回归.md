```python
import math
import numpy as np
import torch
from torch import nn
from d2l import torch as d2l
```


```python
#生成数据集
max_degree = 20 #多项式的最大阶数
n_train,n_test = 100,100#训练数据集和测试数据集的大小
true_w = np.zeros(max_degree)#分配大量的空间
true_w[0:4] = np.array([5,1.2,-3.4,5.6])

features = np.random.normal(size=(n_train+n_test,1))
np.random.shuffle(features)

poly_features = np.power(features,np.arange(max_degree).reshape(1,-1))
#生成多项式特征，对每个特征 x 计算 x^0, x^1, ..., x^19。np.arange(max_degree)生成 0 到 19 的数组。reshape(1,-1)将其转换为行向量。
#最终 poly_features 的形状为 (200, 20)

for i in range(max_degree):
    poly_features[:,i]/=math.gamma(i+1)#gamma(n)=(n-1)!
#poly_features[:, i] 是 NumPy 数组的索引操作，表示选取 poly_features 数组中所有行的第 i 列元素。
#在原程序中，poly_features[:,i] /= math.gamma(i+1) 这行代码的作用是对多项式特征进行归一化处理，通过对每一列（阶数相同）除以阶乘（i!）来平衡不同阶数特征的数值规模
    
#labels的维度:(n_train+n_test,)
labels = np.dot(poly_features,true_w)
#理论值 = 5×(x⁰/0!) + 1.2×(x¹/1!) - 3.4×(x²/2!) + 5.6×(x³/3!)
labels += np.random.normal(scale=0.1,size=labels.shape)
#噪声服从均值为 0、标准差为 0.1 的正态分布。
```


```python
#NumPyndarray转换为tensor
true_w,features,poly_features,labels = [torch.tensor(x,dtype=torch.float32) for x in [true_w,features,poly_features,labels]]
```


```python
features[:2],poly_features[:2,:],labels[:2]
```




    (tensor([[0.1997],
             [0.0131]]),
     tensor([[1.0000e+00, 1.9974e-01, 1.9949e-02, 1.3282e-03, 6.6324e-05, 2.6496e-06,
              8.8205e-08, 2.5169e-09, 6.2842e-11, 1.3947e-12, 2.7858e-14, 5.0585e-16,
              8.4201e-18, 1.2937e-19, 1.8458e-21, 2.4579e-23, 3.0684e-25, 3.6053e-27,
              4.0007e-29, 4.2059e-31],
             [1.0000e+00, 1.3149e-02, 8.6444e-05, 3.7888e-07, 1.2454e-09, 3.2752e-12,
              7.1774e-15, 1.3482e-17, 2.2159e-20, 3.2373e-23, 4.2566e-26, 5.0881e-29,
              5.5752e-32, 5.6390e-35, 5.2961e-38, 4.6425e-41, 3.7835e-44, 0.0000e+00,
              0.0000e+00, 0.0000e+00]]),
     tensor([4.9662, 5.0220]))




```python
#对模型进行训练和测试
#评估模型在给定数据集上的损失
def evaluate_loss(net,data_iter,loss):#@save
    """评估给定数据集上模型的损失"""
    metric = d2l.Accumulator(2)#损失的总和，样本数量
    for X,y in data_iter:
        out = net(X)
        y = y.reshape(out.shape)
        l = loss(out,y)
        metric.add(l.sum(),l.numel())
    return metric[0]/metric[1]
```


```python
#定义训练函数
def train(train_features,test_features,train_labels,test_labels,num_epochs=400):
    loss = nn.MSELoss(reduction='none')
    input_shape = train_features.shape[-1]
    #不设置偏置，因为已经在多项式中实现了它
    net = nn.Sequential(nn.Linear(input_shape,1,bias=False))
    batch_size = min(10,train_labels.shape[0])
    train_iter = d2l.load_array((train_features,train_labels.reshape(-1,1)),batch_size)
    test_iter = d2l.load_array((test_features,test_labels.reshape(-1,1)),batch_size,is_train=False)
    trainer = torch.optim.SGD(net.parameters(),lr=0.01)
    animator = d2l.Animator(xlabel='epoch',ylabel='loss',yscale='log',xlim=[1,num_epochs],ylim=[1e-3,1e2],legend=['train','test'])
    for epoch in range(num_epochs):
        d2l.train_epoch_ch3(net,train_iter,loss,trainer)
        if epoch == 0 or (epoch + 1) % 20 == 0:
            animator.add(epoch + 1,(evaluate_loss(net,train_iter,loss),evaluate_loss(net,test_iter,loss)))
    print('weight:',net[0].weight.data.numpy())
```


```python
train(poly_features[:n_train,:4],poly_features[n_train:,:4],labels[:n_train],labels[n_train:])
```

    weight: [[ 4.9990897  1.2059486 -3.3883896  5.5861692]]
    


    
![svg](output_6_1.svg)
    



```python

```
