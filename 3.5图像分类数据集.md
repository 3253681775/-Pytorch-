```python
%matplotlib inline
import torch
import torchvision
from torch.utils import data
from torchvision import transforms
from d2l import torch as d2l

d2l.use_svg_display()
#%matplotlib inline - Jupyter Notebook 的魔法命令，用于将 matplotlib 绘制的图像直接显示在 notebook 中
#导入了 PyTorch 的核心库 torch
#导入了 PyTorch 的计算机视觉库 torchvision
#从 torch.utils.data 导入数据处理相关工具
#从 torchvision 导入数据转换模块 transforms
#导入 d2l 库（《动手学深度学习》配套库）的 PyTorch 接口
#d2l.use_svg_display() - 设置 d2l 库使用 SVG 格式显示图像，通常能获得更清晰的可视化效果
```


```python
#读取数据集
#通过ToTensor实例将图像数据从PIL烈性转换成32浮点数形式
#并除以255使得所有像素的数值均为0-1
# 例如存储到用户目录下的 data 文件夹
import os
data_dir = os.path.expanduser("~/data")  # 扩展为用户目录，如 C:\Users\你的用户名\data
trans = transforms.ToTensor()
mnist_train = torchvision.datasets.FashionMNIST(
    root=data_dir, train=True, transform=trans, download=True
)
mnist_test = torchvision.datasets.FashionMNIST(
    root=data_dir, train=False, transform=trans, download=True
)
```

    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz
    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to C:\Users\32536/data\FashionMNIST\raw\train-images-idx3-ubyte.gz
    

    100.0%
    

    Extracting C:\Users\32536/data\FashionMNIST\raw\train-images-idx3-ubyte.gz to C:\Users\32536/data\FashionMNIST\raw
    
    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz
    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to C:\Users\32536/data\FashionMNIST\raw\train-labels-idx1-ubyte.gz
    

    100.0%
    

    Extracting C:\Users\32536/data\FashionMNIST\raw\train-labels-idx1-ubyte.gz to C:\Users\32536/data\FashionMNIST\raw
    
    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz
    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to C:\Users\32536/data\FashionMNIST\raw\t10k-images-idx3-ubyte.gz
    

    100.0%
    

    Extracting C:\Users\32536/data\FashionMNIST\raw\t10k-images-idx3-ubyte.gz to C:\Users\32536/data\FashionMNIST\raw
    
    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz
    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to C:\Users\32536/data\FashionMNIST\raw\t10k-labels-idx1-ubyte.gz
    

    100.0%

    Extracting C:\Users\32536/data\FashionMNIST\raw\t10k-labels-idx1-ubyte.gz to C:\Users\32536/data\FashionMNIST\raw
    
    

    
    


```python
len(mnist_train),len(mnist_test)
```




    (60000, 10000)




```python
mnist_train[0][0].shape
#高度和宽度均为28像素，数据集由灰度图像组成，其通道数为1
```




    torch.Size([1, 28, 28])




```python
#一下函数用于在数字标签索引及其文本名称之间进行转换
def get_fashion_mnist_labels(labels):#@save
    """返回Fashion-MNIST数据集文本标签"""
    text_labels = ['t-shirt','trouser','pullover','dress','coat','sandal','shirt','sneaker','bag','ankle boot']
    return [text_labels[int(i)] for i in labels]
```


```python
#创建函数可视化这些样本
def show_images(imgs,num_rows,num_cols,titles=None,scale=1.5):#@save
    """绘制图像列表"""
    figsize = (num_cols * scale,num_rows*scale)
    _,axes = d2l.plt.subplots(num_rows,num_cols,figsize=figsize)
    axes = axes.flatten()
    for i,(ax,img) in enumerate(zip(axes,imgs)):
        if torch.is_tensor(img):
            #图像张量
            ax.imshow(img.numpy())
        else:
            #PIL图像
            ax.imshow(img)
        ax.axes.get_xaxis().set_visible(False)
        ax.axes.get_yaxis().set_visible(False)
        if titles:
            ax.set_title(titles[i])
    return axes
```


```python
X,y = next(iter(data.DataLoader(mnist_train,batch_size=18)))
# 作用：从 mnist_train（Fashion-MNIST 训练集）中，一次性读取 18 个样本（图像 + 标签），分别存储到 X（图像数据）和 y（标签数据）中。

# DataLoader 是 PyTorch 用于 “批量加载数据集” 的工具，它的核心作用是：将原始数据集（如 mnist_train，是 Dataset 类型）转换为 可迭代的批量数据生成器，
#方便后续训练时按批次读取数据。这里的关键参数：
#mnist_train：输入的原始数据集（之前通过 torchvision.datasets.FashionMNIST 加载的训练集）。
#batch_size=18：每次读取的样本数量（即 “批次大小”），这里设置为 18，意味着每次会从训练集中取 18 张图像和对应的 18 个标签。
# DataLoader 对象本身是 “可迭代对象”（类似列表），但需要通过 iter() 函数将其转换为 迭代器（Iterator），才能使用 next() 函数获取 “下一个批次” 的数据。
# next(迭代器) 函数的作用是：从迭代器中取出 下一个元素（这里的 “元素” 是一个 (图像批量, 标签批量) 的元组）。
#由于我们是第一次调用 next()，会直接获取 第一个批次 的数据，并通过解构赋值 X, y = ... 分别存储：
#X：18 张图像的批量数据，是 PyTorch 张量，形状为 (batch_size, channel, height, width) → 即 (18, 1, 28, 28)。
#解释形状：18 个样本、1 个通道（灰度图，无 RGB 彩色通道）、每张图 28×28 像素。#
#y：18 个对应的数字标签，是 PyTorch 张量，形状为 (18,)，每个元素是 0-9 的整数（对应 10 类衣物）。

show_images(X.reshape(18,28,28),2,9,titles=get_fashion_mnist_labels(y));
# 原始 X 的形状是 (18, 1, 28, 28)（批量数，通道数，高，宽），但 show_images 函数（以及 matplotlib 的 imshow）需要的图像格式是 (样本数，高，宽)（单通道灰度图无需保留通道维度）。
#reshape(18, 28, 28) 的作用：将 X 从 4 维张量 (18,1,28,28) 压缩为 3 维张量 (18,28,28)，
#相当于 “去掉通道维度”（因为通道数为 1，不影响图像内容）让 show_images 能正确识别每张图像的像素矩阵。
# show_images 函数的第 2、3 个参数分别是 num_rows（行数）和 num_cols（列数）：
#这里 num_rows=2、num_cols=9 → 总共 2×9=18 个子图，正好匹配 18 个样本，确保每个样本对应一个子图，无遗漏也不浪费。
# y 是原始的数字标签（如 [0, 2, 5, ...]），需要通过 get_fashion_mnist_labels(y) 转换为 人类可理解的文本类别（如 ["t-shirt", "pullover", "sandal", ...]）。
#get_fashion_mnist_labels(y) 会接收形状为 (18,) 的标签张量 y，返回一个长度为 18 的列表，每个元素是对应衣物的英文名称。
```


    
![svg](output_6_0.svg)
    



```python
def load_data_fashion_mnist(batch_size,resize=None):#@save
    """下载Fashion-MNIST数据集，然后将其加载到内存中"""
    trans = [transforms.ToTensor
```
