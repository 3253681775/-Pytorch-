```python
%matplotlib inline
import torch
from torch import nn
from d2l import torch as d2l
```


```python
n_train,n_test,num_inputs,batch_size = 20,100,200,5
true_w,true_b = torch.ones((num_inputs,1))*0.01,0.05
train_data = d2l.synthetic_data(true_w,true_b,n_train)
train_iter = d2l.load_array(train_data,batch_size)
test_data = d2l.synthetic_data(true_w,true_b,n_test)
test_iter = d2l.load_array(test_data,batch_size,is_train=False)
```


```python
def init_params():
    w = torch.normal(0,1,size = (num_inputs,1),requires_grad=True)
    b = torch.zeros(1,requires_grad=True)
    return [w,b]
```


```python
#定义L2范数乘法
def l2_penalty(w):
    return torch.sum(w.pow(2))/2
    
```


```python
def train(lambd):
    w,b = init_params()
    net,loss = lambda X:d2l.linreg(X,w,b),d2l.squared_loss
    num_epochs,lr = 100,0.03
    animator = d2l.Animator(xlabel='epochs',ylabel='loss',yscale='log',xlim=[5,num_epochs],legend=['train','test'])
    for epoch in range(num_epochs):
        for X,y in train_iter:
            #增加了l2范数惩罚项
            #广播机制使l2_penalty(w)成为一个长度为batch_size的向量
            l = loss(net(X),y)+lambd*l2_penalty(w)
            l.sum().backward()
            d2l.sgd([w,b],lr,batch_size)
        if (epoch+1)%5 == 0:
            animator.add(epoch+1,(d2l.evaluate_loss(net,train_iter,loss),d2l.evaluate_loss(net,test_iter,loss)))
    print('w的l2范数是:',torch.norm(w).item())
```


```python
#忽略正则化直接训练
train(lambd=0)
```

    w的l2范数是: 14.672799110412598
    


    
![svg](output_5_1.svg)
    



```python
train(lambd=3)
```

    w的l2范数是: 0.04547073692083359
    


    
![svg](output_6_1.svg)
    



```python
#简洁实现
def train_concise(wd):
    net = nn.Sequential(nn.Linear(num_inputs,1))
    for param in net.parameters():
        param.data.normal_()
    loss = nn.MSELoss(reduction='none')
    num_epochs,lr = 100,0.003
    #偏执参数没有衰减
    
    trainer = torch.optim.SGD([{'params':net[0].weight,'weight_decay':wd},{'params':net[0].bias}],lr=lr)
     # 定义优化器（随机梯度下降SGD），关键是对不同参数设置不同的权重衰减：
    # - 对线性层的权重（weight）应用权重衰减wd
    # - 对偏置（bias）不应用权重衰减（默认weight_decay=0）

    animator = d2l.Animator(xlabel='epochs',ylabel='loss',yscale='log',xlim=[5,num_epochs],legend=['train','test'])
    for epoch in range(num_epochs):
        for X,y in train_iter:
            trainer.zero_grad()# 清空梯度（避免累积）
            l = loss(net(X),y)
            l.mean().backward() # 损失取平均值后反向传播（计算梯度）
            trainer.step() # 优化器更新参数（应用梯度下降）

             # 每5个轮次记录一次损失
        if (epoch + 1)%5 == 0:
            animator.add(epoch + 1,(d2l.evaluate_loss(net,train_iter,loss),# 计算训练损失
                                    d2l.evaluate_loss(net,test_iter,loss))) # 计算测试损失
    print('w的l2范数:',net[0].weight.norm().item())
```


```python
train_concise(0)
```

    w的l2范数: 13.441768646240234
    


    
![svg](output_8_1.svg)
    



```python
train_concise(3)

```

    w的l2范数: 0.3977438807487488
    


    
![svg](output_9_1.svg)
    



```python

```
