```python
import numpy as np
import torch
from torch.utils import data
from d2l import torch as d2l
```


```python

```


```python
#生成数据集
true_w = torch.tensor([2,-3.4])
true_b = 4.2
features,labels = d2l.synthetic_data(true_w,true_b,1000)

```


```python
#读取数据集
def loary_array(data_arrays,batch_size,is_train=True):#@save
    """构造一个pytorch数据迭代器"""
    dataset = data.TensorDataset(*data_arrays)
    #它是 torch.utils.data.Dataset 的一个子类，专门用于处理由张量组成的数据。
    #当你有多个张量（如特征、标签等）且这些张量的第一维长度相同时（即样本数量相同），TensorDataset 会将它们按样本维度对齐，形成一个数据集。
    return data.DataLoader(dataset,batch_size,shuffle=is_train)
    #是的，当使用 DataLoader 且 shuffle=True 时，大致流程是：先将整个数据集打乱顺序，然后按 batch_size 从打乱后的数据集里依次截取数据形成批次。
batch_size = 10
data_iter = loary_array((features,labels),batch_size)
```


```python
#定义模型
from torch import nn#nn是神经网络的缩写
net = nn.Sequential(nn.Linear(2,1))
#这是一个容器类，用于按顺序堆叠神经网络层。它会将传入的层按顺序连接起来，前一层的输出会自动作为后一层的输入，简化了模型搭建流程。
#这是一个线性层（也叫全连接层），表示一个线性变换：y = wx + b，其中：第一个参数 2：输入特征的维度（因为我们的数据集每个样本有 2 个特征）
#第二个参数 1：输出特征的维度（这里是线性回归，输出一个预测值）
#这个线性层会自动初始化两个参数：权重 w：形状为 (1, 2)（因为输入 2 维，输出 1 维）偏置 b：形状为 (1,) 的标量
```


```python
#初始化模型参数
net[0].weight.data.normal_(0,0.01)
#net[0]：访问nn.Sequential容器中的第一个（也是唯一一个）层，即我们定义的nn.Linear(2, 1)线性层
#.weight：获取该线性层的权重参数w（形状为(1, 2)）
#.data：表示直接操作参数的值（在 PyTorch 中，参数通常封装在Parameter对象中，.data可以获取其底层张量）
#.normal_(0, 0.01)：这是一个原地操作（方法名末尾有_表示原地修改），将权重参数初始化为服从均值为 0、标准差为 0.01 的正态分布的随机值
net[0].bias.data.fill_(0)
#.bias：获取该线性层的偏置参数b（形状为(1,)）
#.fill_(0)：也是一个原地操作，将偏置参数全部填充为 0
```




    tensor([0.])




```python
#定义损失函数
loss = nn.MSELoss()
#Mean Squared Error Loss均方损失误差
```


```python
#定义优化算法
trainer = torch.optim.SGD(net.parameters(),lr=0.03)
#torch.optim 模块封装了各种经典的优化算法，其核心作用是：根据损失函数对参数的梯度，自动调整模型参数，使模型预测结果尽可能接近真实标签
# net.parameters()：传入模型中需要被优化的参数（即我们要更新的权重 w 和偏置 b）。net.parameters() 会自动收集模型中所有可训练的参数。
```


```python
#训练
num_epochs = 3
for epoch in range(num_epochs):
    for X,y in data_iter:
        l = loss(net(X),y)
        #net(X) 使用当前最新的参数（初始时是随机值，后续是上一轮更新后的值）计算预测结果。
        #每次内层循环（每个批次）结束后，参数（w 和 b）都会被 trainer.step() 直接修改。
        #下一次调用 net(X) 时，会立即使用更新后的参数，因此预测结果会逐步优化（损失逐渐减小）
        trainer.zero_grad()
        l.backward()
        #在 PyTorch 中，模型的参数（如 w 和 b）被封装为 torch.nn.Parameter 对象，这类对象有一个特殊的 .grad 属性，专门用于存储该参数的梯度。
        #当我们执行 l.backward() 时：
        #反向传播会沿着损失 l 对所有参与计算的参数（通过 net.parameters() 收集的参数）计算梯度。
        #计算出的梯度会自动存储到对应参数的 .grad 属性中（例如 net[0].weight.grad 和 net[0].bias.grad）。
        #也就是说，梯度并非存储在损失 l 中，而是直接绑定到参数本身。
        trainer.step()
        #在定义优化器时，我们传入了 net.parameters()：
        #net.parameters() 会返回模型中所有可训练的参数（即 w 和 b），优化器会 “记住” 这些参数。
        #当调用 trainer.step() 时，优化器会遍历它所 “记住” 的所有参数，读取每个参数的 .grad 属性（即 l.backward() 计算出的梯度），然后按照 SGD 公式更新参数。
    l = loss(net(features),labels)
    print(f'epoch{epoch + 1},loss{l:f}')
# 对每个批次执行一次完整的 “前向传播→梯度清零→反向传播→参数更新” 流程：
#前向传播：模型根据输入 X 计算预测值，再通过损失函数 loss 与真实标签 y 比较，得到当前批次的损失 l
#梯度清零：trainer.zero_grad() 清除上一次迭代积累的梯度，避免干扰当前计算
#反向传播：l.backward() 自动计算损失 l 对模型所有参数（w 和 b）的梯度
#参数更新：trainer.step() 根据计算出的梯度，使用 SGD 算法更新参数（使损失更小）
```

    epoch1,loss0.000312
    epoch2,loss0.000096
    epoch3,loss0.000096
    


```python
w = net[0].weight.data
print('w的估计误差：',true_w - w.reshape(true_w.shape),'true_w:',w)
b = net[0].bias.data
print('b的估计误差：',true_b - b,'true_b:',b)
```

    w的估计误差： tensor([ 7.4613e-04, -9.7752e-05]) true_w: tensor([[ 1.9993, -3.3999]])
    b的估计误差： tensor([-0.0002]) true_b: tensor([4.2002])
    


```python
#练习
#（1）
#1. 核心依据：nn.MSELoss 的默认行为
#nn.MSELoss 是 PyTorch 中实现均方误差（Mean Squared Error, MSE）的损失函数，其计算逻辑由参数 reduction 控制（默认值为 'mean'）：
#当 reduction='mean'（默认）：先计算每个样本的 MSE（(预测值-真实值)²），再对小批量内所有样本的 MSE 取平均值，得到 “小批量平均损失”。
#当 reduction='sum'：仅计算小批量内所有样本 MSE 的总和，得到 “小批量总损失”。
#当 reduction='none'：不做聚合，返回每个样本各自的 MSE（形状与小批量样本数一致）。
#你的代码中未指定 reduction，因此使用默认的 'mean'，即计算小批量损失的平均值。
```


```python

```
